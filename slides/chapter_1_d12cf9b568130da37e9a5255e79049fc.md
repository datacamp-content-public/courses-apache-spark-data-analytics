---
title: Insert title here
key: d12cf9b568130da37e9a5255e79049fc

---
## Train/Test Split

```yaml
type: "TitleSlide"
key: "128ea939d1"
```

`@lower_third`

name: Andrew Collier
title: undefined


`@script`



---
## Why Split the Data?

```yaml
type: "FullSlide"
key: "9fd5091180"
```

`@part1`
We split the data into two sets so that we can objectively evaluate our model.

Typically split in ratio 4:1 giving

- training set (80% of original data) and
- testing set (20% of original data).

Then train model on the training set and evaluate it on the testing set.

**Note:** The split must be *randomised* so that it does not introduce bias.


`@script`



---
## The Data

```yaml
type: "FullSlide"
key: "593ca7db42"
```

`@part1`
We've already loaded some data as a Spark `DataFrame`.

```
>>> type(power)
pyspark.sql.dataframe.DataFrame
```

We assembled the data into two components: `features` and `power`.

```
>>> power.take(3)
[Row(features=DenseVector([14.96, 41.76, 1024.07, 73.17]), power=463.26),
 Row(features=DenseVector([25.18, 62.96, 1020.04, 59.08]), power=444.37),
 Row(features=DenseVector([5.11, 39.4, 1012.16, 92.14]), power=488.56)]
```


`@script`
We will use the `features` to predict `power`.


---
## Size of Data

```yaml
type: "FullSlide"
key: "8a6cf67fd9"
```

`@part1`
How many records are there in the data?

```
>>> power.count()
9568
```

We need split them them into two sets: train and test.


`@script`



---
## Split the Data

```yaml
type: "FullSlide"
key: "5e0fb8ab96"
```

`@part1`
Use the `randomSplit()` method to split the data.

```
>>> train, test = power.randomSplit([0.8, 0.2], seed=13)
```

Always specify a value for `seed` so that the split is reproducible.

Check on size of `train` and `test`.

```
>>> (train.count(), test.count())
(7608, 1960)
```


`@script`



---
## Let's try that out!

```yaml
type: "FinalSlide"
key: "ec766569c9"
```

`@script`


